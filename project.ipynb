{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.misc import imresize\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "# Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "# Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Full connection\n",
    "classifier.add(Dense(units = 64, activation = 'relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(units = 5, activation='softmax'))\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36 images belonging to 5 classes.\n",
      "Found 18 images belonging to 5 classes.\n",
      "Epoch 1/5\n",
      " - 856s - loss: 1.1224 - acc: 0.5475 - val_loss: 0.9624 - val_acc: 0.7222\n",
      "Epoch 2/5\n",
      " - 825s - loss: 0.5616 - acc: 0.8159 - val_loss: 0.7119 - val_acc: 0.7222\n",
      "Epoch 3/5\n",
      " - 897s - loss: 0.4046 - acc: 0.8731 - val_loss: 0.9511 - val_acc: 0.7778\n",
      "Epoch 4/5\n",
      " - 877s - loss: 0.3480 - acc: 0.8998 - val_loss: 1.0336 - val_acc: 0.7778\n",
      "Epoch 5/5\n",
      " - 817s - loss: 0.2725 - acc: 0.9203 - val_loss: 1.2240 - val_acc: 0.7222\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "`save_model` requires h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-45e7923c93a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                          \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                          verbose = 2)\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cnn_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   2589\u001b[0m         \"\"\"\n\u001b[1;32m   2590\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2591\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2593\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`save_model` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_json_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: `save_model` requires h5py."
     ]
    }
   ],
   "source": [
    "# Fitting the CNN to the images\n",
    "train_datagen = image.ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=180,\n",
    "                                   width_shift_range=0.3,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "test_datagen = image.ImageDataGenerator(rescale=1./255)\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                  target_size = (64, 64),\n",
    "                                                  batch_size = 32,\n",
    "                                                  class_mode = 'categorical')\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                             target_size = (64, 64),\n",
    "                                             batch_size = 32,\n",
    "                                             class_mode = 'categorical')\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 250,\n",
    "                         epochs = 5,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 500,\n",
    "                         verbose = 2)\n",
    "classifier.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "`save_weights` requires h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-230dbb03a8a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cnn_weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`save_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m         \u001b[0;31m# If file exists and should not be overwritten:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moverwrite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: `save_weights` requires h5py."
     ]
    }
   ],
   "source": [
    "classifier.save_weights('cnn_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making new predictions\n",
    "count = 0\n",
    "for i in range(1, 15):\n",
    "    test_image = image.load_img('dataset/single_prediction/cat_or_dog_{}.jpg'.format(i), target_size = (64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = classifier.predict(test_image)\n",
    "    training_set.class_indices\n",
    "    print(result)\n",
    "    if result[0][0] == 1:\n",
    "        count += 1\n",
    "        prediction = 'dog'\n",
    "    else:\n",
    "        prediction = 'cat'\n",
    "    plt.title(prediction)\n",
    "    plt.imshow(test_image[0].astype(float))\n",
    "    plt.show()\n",
    "print(count/14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "classifier.save_weights('weights.h5')\n",
    "\n",
    "# Save the model architecture\n",
    "with open('catdog_architecture.json', 'w') as f:\n",
    "    f.write(classifier.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "`load_weights` requires h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9df203c36eed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load weights into the new model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'catdog_weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: `load_weights` requires h5py."
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# Model reconstruction from JSON file\n",
    "with open('catdog_architecture.json', 'r') as f:\n",
    "    model = model_from_json(f.read())\n",
    "\n",
    "# Load weights into the new model\n",
    "model.load_weights('catdog_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def backproject(source, target, levels = 2, scale = 1):\n",
    "    hsv = cv2.cvtColor(source,\tcv2.COLOR_BGR2HSV)\n",
    "    hsvt = cv2.cvtColor(target,\tcv2.COLOR_BGR2HSV)\n",
    "    # calculating object histogram\n",
    "    roihist = cv2.calcHist([hsv],[0, 1], None, [levels, levels], [0, 180, 0, 256] )\n",
    "\n",
    "    # normalize histogram and apply backprojection\n",
    "    cv2.normalize(roihist,roihist,0,255,cv2.NORM_MINMAX)\n",
    "    dst = cv2.calcBackProject([hsvt],[0,1],roihist,[0,180,0,256], scale)\n",
    "    return dst\n",
    "\n",
    "def saliency_by_backprojection(img):\n",
    "    cv2.pyrMeanShiftFiltering(img, 2, 10, img, 4)\n",
    "\n",
    "    backproj = np.uint8(backproject(img, img, levels = 2))\n",
    "    cv2.normalize(backproj,backproj,0,255,cv2.NORM_MINMAX)\n",
    "    saliencies = [backproj, backproj, backproj]\n",
    "    saliency = cv2.merge(saliencies)\n",
    "\n",
    "    cv2.pyrMeanShiftFiltering(saliency, 20, 200, saliency, 2)\n",
    "    saliency = cv2.cvtColor(saliency, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.equalizeHist(saliency, saliency)\n",
    "\n",
    "    return 255-saliency\n",
    "\n",
    "def saliency_map(img):\n",
    "    saliency_hsv = saliency_by_backprojection(img * 1)\n",
    "    saliency = saliency_hsv\n",
    "    (T, saliency) = cv2.threshold(saliency, 200, 255, cv2.THRESH_BINARY)\n",
    "    return saliency\n",
    "\n",
    "def largest_contours_rect(saliency):\n",
    "    _, contours, hierarchy = cv2.findContours(saliency * 1,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key = cv2.contourArea)\n",
    "    return cv2.boundingRect(contours[-1])\n",
    "\n",
    "def refine_saliency_with_grabcut(img, saliency):\n",
    "    rect = largest_contours_rect(saliency)\n",
    "    bgdmodel = np.zeros((1, 65),np.float64)\n",
    "    fgdmodel = np.zeros((1, 65),np.float64)\n",
    "    saliency[np.where(saliency > 0)] = cv2.GC_FGD\n",
    "    mask = saliency\n",
    "    try:\n",
    "        cv2.grabCut(img, mask, rect, bgdmodel, fgdmodel, 1, cv2.GC_INIT_WITH_RECT)\n",
    "    except:\n",
    "        pass\n",
    "    mask = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "    return mask\n",
    "\n",
    "def backprojection_saliency(img):\n",
    "    saliency = saliency_map(img)\n",
    "    mask = refine_saliency_with_grabcut(img, saliency)\n",
    "    return mask\n",
    "\n",
    "def bounding_box(mask):\n",
    "    obj = np.where(mask != 0)\n",
    "    bbox = np.min(obj[0]), np.max(obj[0]), np.min(obj[1]), np.max(obj[1])\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"flower_original.jpg\", 1)\n",
    "img = cv2.resize(img, (640, 480))\n",
    "mask = backprojection_saliency(img)\n",
    "segmentation = img*mask[:,:,np.newaxis]\n",
    "plt.imshow(mask)\n",
    "# plt.imshow(segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.count_nonzero(mask), mask.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib inline\n",
    "vc = cv2.VideoCapture(0)\n",
    "\n",
    "if vc.isOpened(): # try to get the first frame\n",
    "    is_capturing, frame = vc.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)    # makes the blues image look real colored\n",
    "    webcam_preview = plt.imshow(frame)   \n",
    "else:\n",
    "    is_capturing = False\n",
    "\n",
    "while is_capturing:\n",
    "    try:    # Lookout for a keyboardInterrupt to stop the script\n",
    "        is_capturing, frame = vc.read()\n",
    "        frame_big = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)    # makes the blues image look real colored\n",
    "        frame = imresize(frame_big, (180,320))\n",
    "        mask = backprojection_saliency(frame)\n",
    "        segmentation = frame*mask[:,:,np.newaxis]\n",
    "        bbox = bounding_box(mask)\n",
    "        frame[bbox[0]:bbox[1],bbox[2]:bbox[3],1] = np.clip(2 * frame[bbox[0]:bbox[1],bbox[2]:bbox[3],1], None, 255)\n",
    "        webcam_preview.set_data(frame)\n",
    "        plt.draw()\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "\n",
    "        plt.pause(1)    # the pause time is = 1 / framerate\n",
    "    except KeyboardInterrupt:\n",
    "        vc.release()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
